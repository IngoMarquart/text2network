[Paths]
import_folder=/example/data
database=/example/database/db.h5
pretrained_bert=/example/pretrained_bert
trained_berts=/example/trained_berts
processing_cache=/example/process_cache
log=/example/log

[NeoConfig]
db_uri =bolt://localhost:7687
db_db = neo4j
db_pwd = nlp
protocol = http
http_uri = http://localhost:7474

[General]
logging_level = 10
split_hierarchy=["year","p1"]
neo_batch_size = 100

[Preprocessing]
max_seq_length = 40
number_params=1
char_mult=10
split_symbol=_

[BertTraining]
new_word_cutoff=10
mlm_probability=0.2
max_seq_length = 40
gpu_batch = 5
epochs = 1000
warmup_steps = 0
save_steps = 5000000
eval_steps=100
eval_loss_limit=0.5
loss_limit = 0.4

[Processing]
cutoff_percent=90
context_cutoff_percent=80
max_degree=25
context_max_degree=10
batch_size=1
prune_missing_tokens = True
maxn = 0
nr_workers = 0
cutoff_prob = 0.01