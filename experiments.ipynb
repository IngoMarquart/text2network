{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/text2network/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ingomarquart/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "INFO:t2n:Found 2 directories in data path.\n",
      "DEBUG:t2n:Loading data in directory: 2022\n",
      "DEBUG:t2n:Found 3 json files in directory.\n",
      "DEBUG:t2n:Loading data in directory: 2000\n",
      "DEBUG:t2n:Found 2 json files in directory.\n",
      "INFO:t2n:Found 2 LLMs to train.\n",
      "DEBUG:t2n:LLM: ['2022', '2000']\n",
      "DEBUG:t2n:Creating dataset for LLM: 2022\n",
      "DEBUG:t2n:Found 3 json files for LLM.\n",
      "WARNING:datasets.builder:Found cached dataset json (/Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-0a944613b0574bc6/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 209.61it/s]\n",
      "DEBUG:t2n:Loaded dataset for LLM: 2022\n",
      "DEBUG:t2n:Splitting dataset for LLM: 2022\n",
      "DEBUG:t2n:Split dataset for LLM: 2022\n"
     ]
    }
   ],
   "source": [
    "from text2network.datasets.text_datasets import *\n",
    "config = TrainingConfig(data_path=\"data/preprocessed/\", output_folder=\"data/berts\", logging_level=10, sequence_batch=2, new_word_cutoff=5)\n",
    "pts = PreTrainDataSet(config)\n",
    "dataset = pts.make_dataset(\"2022\")\n",
    "tokenizer = FakeTokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:t2n:Creating dataset for LLM: 2022\n",
      "DEBUG:t2n:Found 3 json files for LLM.\n",
      "WARNING:datasets.builder:Found cached dataset json (/Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-0a944613b0574bc6/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 302.47it/s]\n",
      "DEBUG:t2n:Loaded dataset for LLM: 2022\n",
      "DEBUG:t2n:Getting missing tokens for LLM: 2022\n",
      "DEBUG:t2n:Applying NLTK ops for LLM: 2022\n",
      "WARNING:datasets.fingerprint:Parameter 'function'=<function PreTrainDataSet.get_missing_freq_table.<locals>.apply_nltk_ops at 0x104268d30> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "DEBUG:t2n:Filtering missing tokens for LLM: 2022               \n",
      "DEBUG:t2n:Mapping batched freq table for LLM: 2022                \n",
      "DEBUG:t2n:Combining freq tables for LLM: 2022                  \n",
      "                                                  \r"
     ]
    }
   ],
   "source": [
    "dd = pts.get_missing_freq_table(llm=\"2022\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:t2n:Creating dataset for LLM: 2022\n",
      "DEBUG:t2n:Found 3 json files for LLM.\n",
      "WARNING:datasets.builder:Found cached dataset json (/Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-0a944613b0574bc6/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 119.63it/s]\n",
      "DEBUG:t2n:Loaded dataset for LLM: 2022\n",
      "DEBUG:t2n:Getting missing tokens for LLM: 2022\n",
      "DEBUG:t2n:Applying NLTK ops for LLM: 2022\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-0a944613b0574bc6/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-99334906d784c41f_*_of_00004.arrow\n",
      "DEBUG:t2n:Filtering missing tokens for LLM: 2022\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-0a944613b0574bc6/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-de7e4dcef3a32649_*_of_00004.arrow\n",
      "DEBUG:t2n:Mapping batched freq table for LLM: 2022\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-0a944613b0574bc6/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-fbc6e420638d2084_*_of_00004.arrow\n",
      "DEBUG:t2n:Combining freq tables for LLM: 2022\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-0a944613b0574bc6/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-a836ca8331dcbbf0.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-0a944613b0574bc6/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-5cf27601b3c69891.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-0a944613b0574bc6/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-ec9fd913f4be8b7d.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-0a944613b0574bc6/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-37881328aaf0bcd6.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-0a944613b0574bc6/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-5eee75cf3e3f67c0.arrow\n",
      "DEBUG:t2n:Creating dataset for LLM: 2000\n",
      "DEBUG:t2n:Found 2 json files for LLM.\n",
      "WARNING:datasets.builder:Found cached dataset json (/Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-1680d4171777f2ee/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 58.07it/s]\n",
      "DEBUG:t2n:Loaded dataset for LLM: 2000\n",
      "DEBUG:t2n:Getting missing tokens for LLM: 2000\n",
      "DEBUG:t2n:Applying NLTK ops for LLM: 2000\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-1680d4171777f2ee/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-53250e3a6c68f834_*_of_00004.arrow\n",
      "DEBUG:t2n:Filtering missing tokens for LLM: 2000\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-1680d4171777f2ee/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-fc24bae413354120_*_of_00004.arrow\n",
      "DEBUG:t2n:Mapping batched freq table for LLM: 2000\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-1680d4171777f2ee/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-8b20f9e4e453812a_*_of_00004.arrow\n",
      "DEBUG:t2n:Combining freq tables for LLM: 2000\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-1680d4171777f2ee/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-bb6dfbc11af9dfeb.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-1680d4171777f2ee/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-9aa216705957d399.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-1680d4171777f2ee/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-670bc4ade606cafe.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-1680d4171777f2ee/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-32ce777f881357a4.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /Users/ingomarquart/Documents/GitHub/text2network/cache/json/default-1680d4171777f2ee/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-fa5cb1c453348dc6.arrow\n"
     ]
    }
   ],
   "source": [
    "dd = pts.get_missing_tokens(llm_list =  pts.llms, tokenizer=tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text2network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
